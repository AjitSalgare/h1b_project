6) Find the percentage and the count of each case status on total applications for each year. Create a line graph depicting the pattern of All the cases over the period of time.(using mapreduce)

Program:
package h1b_Q6

import java.io.*;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.mapreduce.lib.input.*;
import org.apache.hadoop.mapreduce.lib.output.*;



	public static class MapClass extends Mapper<LongWritable,Text,Text,Text>
	   {
	      public void map(LongWritable key, Text value, Context context)
	      {	    	  
	         try{
	            String[] str = value.toString().split("\t");	 
	            String  year = str[7];
	            String case_status = str[1];
	            context.write(new Text(year),new Text(case_status));
	            }
	         catch(Exception e)
	         {
	            System.out.println(e.getMessage());
	         }
	      }
	   }
	  public static class ReduceClass extends Reducer<Text,Text,Text,Text>
	   {
		   
		    
		    public void reduce(Text key, Iterable<Text> values,Context context) throws IOException, InterruptedException
 {
 long totalcount= 0,certified_count=0,certified_withdrawn_count=0,denied_count=0,withdrawn_count=0;	
double certified_AvgPerc=0,certified_withdrawn_AvgPerc=0,denied_AvgPerc=0,withdrawn_AvgPerc=0;	
	  for (Text T : values)
		  {    
		        	 totalcount++;
String case_status=T.toString();
						if(case_status.equals("CERTIFIED"))
						{
							certified_count++;
						}
else if(case_status.equals("CERTIFIED-WITHDRAWN"))
						{
							certified_withdrawn_count++;
						}
						else if(case_status.equals("WITHDRAWN"))
						{
							withdrawn_count++;
						}
						else
						{
							denied_count++;
						}
					}
 certified_AvgPerc = ((double)certified_count/(double)totalcount)*100;
certified_withdrawn_AvgPerc = ((double)certified_withdrawn_count/(double)totalcount)*100;
withdrawn_AvgPerc = ((double)withdrawn_count/(double)totalcount)*100;
denied_AvgPerc = ((double)denied_count/(double)totalcount)*100;
String COUNT=totalcount+"\t"+certified_count+"\t"+certified_AvgPerc+"\t"+certified_withdrawn_count+"\t"
			       +certified_withdrawn_AvgPerc+"\t"+withdrawn_count+"\t"+withdrawn_AvgPerc+"\t"+denied_count+"\t"+ denied_AvgPerc;
		     
 context.write(key,new Text(COUNT));
		      }
	   }
      public class percentage_avg 
         {
	
	  public static void main(String[] args) throws Exception {
		    Configuration conf = new Configuration();
		   
		    Job job = new Job(conf, "H1B DATA");
		    job.setJarByClass(percentage_avg.class);
		    job.setMapperClass(MapClass.class);
		    job.setMapOutputKeyClass(Text.class);
		    job.setMapOutputValueClass(Text.class);
		    job.setReducerClass(ReduceClass.class);
		    job.setOutputKeyClass(Text.class);
		    job.setOutputValueClass(Text.class);
		    FileInputFormat.addInputPath(job, new Path(args[0]));
		    FileOutputFormat.setOutputPath(job, new Path(args[1]));
		    System.exit(job.waitForCompletion(true) ? 0 : 1);
		  }


}


Output:
2011	358767	307936	85.83175152675692	11596	3.2321813321738064	10105	2.816591269542628	29130	8.119475871526644
2012	415607	352668	84.85612609989725	31118	7.487361858678993	10725	2.5805628875355806	21096	5.0759491538881685
2013	442114	382951	86.61815730784367	35432	8.014222576077664	11590	2.621495813297023	12141	2.7461243027816358
2014	519427	455144	87.62424748809747	36350	6.99809597883822	16034	3.086863024063054	11899	2.2907935090012645
2015	618727	547278	88.45225761927313	41071	6.637984119005635	19455	3.144359305477214	10923	1.7653989562440302
2016	647803	569646	87.93506667922193	47092	7.269493966529948	21890	3.3791137120389996	9175	1.4163256422091284





